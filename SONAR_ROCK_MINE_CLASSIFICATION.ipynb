{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SONAR_ROCK_MINE_CLASSIFICATION.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPrKZO1q3TcwLnXG14BTCW4"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"CEUtUbTBvORx","colab_type":"code","colab":{}},"source":["# Importing necessary Libraries\n","import numpy \n","import pandas\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"leRXXBljxBEO","colab_type":"code","colab":{}},"source":["# Importing tensorflow 2.x as a backend for keras\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YvyQRmPkC0wB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1581438647390,"user_tz":300,"elapsed":550,"user":{"displayName":"Manoj Malviya","photoUrl":"","userId":"00270539278112484716"}},"outputId":"c1bc777e-1a50-4734-9376-35a1abb090f6"},"source":["Data = pandas.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data',header= None)\n","print(Data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["         0       1       2       3       4   ...      56      57      58      59  60\n","0    0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n","1    0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n","2    0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n","3    0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n","4    0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n","..      ...     ...     ...     ...     ...  ...     ...     ...     ...     ...  ..\n","203  0.0187  0.0346  0.0168  0.0177  0.0393  ...  0.0065  0.0115  0.0193  0.0157   M\n","204  0.0323  0.0101  0.0298  0.0564  0.0760  ...  0.0034  0.0032  0.0062  0.0067   M\n","205  0.0522  0.0437  0.0180  0.0292  0.0351  ...  0.0140  0.0138  0.0077  0.0031   M\n","206  0.0303  0.0353  0.0490  0.0608  0.0167  ...  0.0034  0.0079  0.0036  0.0048   M\n","207  0.0260  0.0363  0.0136  0.0272  0.0214  ...  0.0040  0.0036  0.0061  0.0115   M\n","\n","[208 rows x 61 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x8Uw-0AgDdC0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":431},"executionInfo":{"status":"ok","timestamp":1581439497174,"user_tz":300,"elapsed":306,"user":{"displayName":"Manoj Malviya","photoUrl":"","userId":"00270539278112484716"}},"outputId":"46a9e694-bb6a-4b7d-ee49-88448ca280c1"},"source":["# Defining INPUT and TARGET values for the neural network\n","# Importing SKLEARN libraries for training and test data splitting\n","from sklearn.model_selection import train_test_split\n","import sklearn.preprocessing\n","encoded_rock_or_mine = sklearn.preprocessing.LabelEncoder()\n","Data.R = encoded_rock_or_mine.fit_transform(Data[60])\n","Input = Data.iloc[:,:-1]\n","Target = Data.R\n","Input_train, Input_test, Target_train, Target_test = train_test_split(Input,Target, test_size=0.3)\n","input_size = Input_train.shape[1]\n","# Printing the shapes of target to make sure the splitting is right\n","print(Target_train.shape)\n","print(Target_test.shape)\n","print(Target.shape)\n","print(Target)\n","print(Input)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(145,)\n","(63,)\n","(208,)\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","         0       1       2       3   ...      56      57      58      59\n","0    0.0200  0.0371  0.0428  0.0207  ...  0.0180  0.0084  0.0090  0.0032\n","1    0.0453  0.0523  0.0843  0.0689  ...  0.0140  0.0049  0.0052  0.0044\n","2    0.0262  0.0582  0.1099  0.1083  ...  0.0316  0.0164  0.0095  0.0078\n","3    0.0100  0.0171  0.0623  0.0205  ...  0.0050  0.0044  0.0040  0.0117\n","4    0.0762  0.0666  0.0481  0.0394  ...  0.0072  0.0048  0.0107  0.0094\n","..      ...     ...     ...     ...  ...     ...     ...     ...     ...\n","203  0.0187  0.0346  0.0168  0.0177  ...  0.0065  0.0115  0.0193  0.0157\n","204  0.0323  0.0101  0.0298  0.0564  ...  0.0034  0.0032  0.0062  0.0067\n","205  0.0522  0.0437  0.0180  0.0292  ...  0.0140  0.0138  0.0077  0.0031\n","206  0.0303  0.0353  0.0490  0.0608  ...  0.0034  0.0079  0.0036  0.0048\n","207  0.0260  0.0363  0.0136  0.0272  ...  0.0040  0.0036  0.0061  0.0115\n","\n","[208 rows x 60 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dKuqytc-D1lQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1581442723845,"user_tz":300,"elapsed":172,"user":{"displayName":"Manoj Malviya","photoUrl":"","userId":"00270539278112484716"}},"outputId":"620333bf-8824-478b-9be5-8e548ec357ff"},"source":["# Building a Neural Network with 4 hidden layers (120,60,30,1) hidden nodes with activation function [RELU, RELU, RELU, sigmoid function]\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Dense(60, activation='relu', input_shape = (60,)),\n","        tf.keras.layers.Dense(30, activation='relu'),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n","    model.summary()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_102 (Dense)            (None, 60)                3660      \n","_________________________________________________________________\n","dense_103 (Dense)            (None, 30)                1830      \n","_________________________________________________________________\n","dense_104 (Dense)            (None, 1)                 31        \n","=================================================================\n","Total params: 5,521\n","Trainable params: 5,521\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kYKMN-MGDuul","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1581442730109,"user_tz":300,"elapsed":4331,"user":{"displayName":"Manoj Malviya","photoUrl":"","userId":"00270539278112484716"}},"outputId":"bc272e58-7312-4100-af8a-47f8df8f6b8f"},"source":["model.fit(Input_train, Target_train, epochs=200)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 145 samples\n","Epoch 1/200\n","145/145 [==============================] - 0s 2ms/sample - loss: 0.7579 - accuracy: 0.5379\n","Epoch 2/200\n","145/145 [==============================] - 0s 111us/sample - loss: 0.7298 - accuracy: 0.5931\n","Epoch 3/200\n","145/145 [==============================] - 0s 100us/sample - loss: 0.7110 - accuracy: 0.5931\n","Epoch 4/200\n","145/145 [==============================] - 0s 112us/sample - loss: 0.7015 - accuracy: 0.5931\n","Epoch 5/200\n","145/145 [==============================] - 0s 98us/sample - loss: 0.6969 - accuracy: 0.5931\n","Epoch 6/200\n","145/145 [==============================] - 0s 96us/sample - loss: 0.6939 - accuracy: 0.5931\n","Epoch 7/200\n","145/145 [==============================] - 0s 101us/sample - loss: 0.6924 - accuracy: 0.5931\n","Epoch 8/200\n","145/145 [==============================] - 0s 102us/sample - loss: 0.6918 - accuracy: 0.5931\n","Epoch 9/200\n","145/145 [==============================] - 0s 106us/sample - loss: 0.6914 - accuracy: 0.5931\n","Epoch 10/200\n","145/145 [==============================] - 0s 105us/sample - loss: 0.6911 - accuracy: 0.5931\n","Epoch 11/200\n","145/145 [==============================] - 0s 92us/sample - loss: 0.6908 - accuracy: 0.5931\n","Epoch 12/200\n","145/145 [==============================] - 0s 98us/sample - loss: 0.6904 - accuracy: 0.5931\n","Epoch 13/200\n","145/145 [==============================] - 0s 151us/sample - loss: 0.6900 - accuracy: 0.5931\n","Epoch 14/200\n","145/145 [==============================] - 0s 103us/sample - loss: 0.6894 - accuracy: 0.5931\n","Epoch 15/200\n","145/145 [==============================] - 0s 96us/sample - loss: 0.6885 - accuracy: 0.5931\n","Epoch 16/200\n","145/145 [==============================] - 0s 103us/sample - loss: 0.6875 - accuracy: 0.5931\n","Epoch 17/200\n","145/145 [==============================] - 0s 121us/sample - loss: 0.6861 - accuracy: 0.5931\n","Epoch 18/200\n","145/145 [==============================] - 0s 101us/sample - loss: 0.6844 - accuracy: 0.5931\n","Epoch 19/200\n","145/145 [==============================] - 0s 103us/sample - loss: 0.6822 - accuracy: 0.5931\n","Epoch 20/200\n","145/145 [==============================] - 0s 115us/sample - loss: 0.6801 - accuracy: 0.6000\n","Epoch 21/200\n","145/145 [==============================] - 0s 159us/sample - loss: 0.6784 - accuracy: 0.6069\n","Epoch 22/200\n","145/145 [==============================] - 0s 86us/sample - loss: 0.6756 - accuracy: 0.6207\n","Epoch 23/200\n","145/145 [==============================] - 0s 86us/sample - loss: 0.6728 - accuracy: 0.6207\n","Epoch 24/200\n","145/145 [==============================] - 0s 92us/sample - loss: 0.6693 - accuracy: 0.6345\n","Epoch 25/200\n","145/145 [==============================] - 0s 90us/sample - loss: 0.6661 - accuracy: 0.6759\n","Epoch 26/200\n","145/145 [==============================] - 0s 145us/sample - loss: 0.6623 - accuracy: 0.7034\n","Epoch 27/200\n","145/145 [==============================] - 0s 133us/sample - loss: 0.6586 - accuracy: 0.7241\n","Epoch 28/200\n","145/145 [==============================] - 0s 89us/sample - loss: 0.6549 - accuracy: 0.7379\n","Epoch 29/200\n","145/145 [==============================] - 0s 106us/sample - loss: 0.6513 - accuracy: 0.7448\n","Epoch 30/200\n","145/145 [==============================] - 0s 150us/sample - loss: 0.6473 - accuracy: 0.7517\n","Epoch 31/200\n","145/145 [==============================] - 0s 131us/sample - loss: 0.6442 - accuracy: 0.7448\n","Epoch 32/200\n","145/145 [==============================] - 0s 125us/sample - loss: 0.6413 - accuracy: 0.7448\n","Epoch 33/200\n","145/145 [==============================] - 0s 114us/sample - loss: 0.6387 - accuracy: 0.7517\n","Epoch 34/200\n","145/145 [==============================] - 0s 134us/sample - loss: 0.6365 - accuracy: 0.7655\n","Epoch 35/200\n","145/145 [==============================] - 0s 106us/sample - loss: 0.6342 - accuracy: 0.7655\n","Epoch 36/200\n","145/145 [==============================] - 0s 100us/sample - loss: 0.6331 - accuracy: 0.7931\n","Epoch 37/200\n","145/145 [==============================] - 0s 158us/sample - loss: 0.6295 - accuracy: 0.7724\n","Epoch 38/200\n","145/145 [==============================] - 0s 110us/sample - loss: 0.6307 - accuracy: 0.7586\n","Epoch 39/200\n","145/145 [==============================] - 0s 98us/sample - loss: 0.6273 - accuracy: 0.7724\n","Epoch 40/200\n","145/145 [==============================] - 0s 118us/sample - loss: 0.6258 - accuracy: 0.8069\n","Epoch 41/200\n","145/145 [==============================] - 0s 126us/sample - loss: 0.6234 - accuracy: 0.8138\n","Epoch 42/200\n","145/145 [==============================] - 0s 122us/sample - loss: 0.6222 - accuracy: 0.7931\n","Epoch 43/200\n","145/145 [==============================] - 0s 107us/sample - loss: 0.6205 - accuracy: 0.8000\n","Epoch 44/200\n","145/145 [==============================] - 0s 88us/sample - loss: 0.6187 - accuracy: 0.8207\n","Epoch 45/200\n","145/145 [==============================] - 0s 106us/sample - loss: 0.6181 - accuracy: 0.8276\n","Epoch 46/200\n","145/145 [==============================] - 0s 93us/sample - loss: 0.6166 - accuracy: 0.8276\n","Epoch 47/200\n","145/145 [==============================] - 0s 132us/sample - loss: 0.6149 - accuracy: 0.8345\n","Epoch 48/200\n","145/145 [==============================] - 0s 121us/sample - loss: 0.6138 - accuracy: 0.8345\n","Epoch 49/200\n","145/145 [==============================] - 0s 128us/sample - loss: 0.6131 - accuracy: 0.8276\n","Epoch 50/200\n","145/145 [==============================] - 0s 102us/sample - loss: 0.6113 - accuracy: 0.8345\n","Epoch 51/200\n","145/145 [==============================] - 0s 116us/sample - loss: 0.6112 - accuracy: 0.8414\n","Epoch 52/200\n","145/145 [==============================] - 0s 113us/sample - loss: 0.6091 - accuracy: 0.8483\n","Epoch 53/200\n","145/145 [==============================] - 0s 111us/sample - loss: 0.6099 - accuracy: 0.8345\n","Epoch 54/200\n","145/145 [==============================] - 0s 123us/sample - loss: 0.6081 - accuracy: 0.8345\n","Epoch 55/200\n","145/145 [==============================] - 0s 100us/sample - loss: 0.6080 - accuracy: 0.8483\n","Epoch 56/200\n","145/145 [==============================] - 0s 104us/sample - loss: 0.6062 - accuracy: 0.8552\n","Epoch 57/200\n","145/145 [==============================] - 0s 110us/sample - loss: 0.6063 - accuracy: 0.8483\n","Epoch 58/200\n","145/145 [==============================] - 0s 96us/sample - loss: 0.6041 - accuracy: 0.8483\n","Epoch 59/200\n","145/145 [==============================] - 0s 141us/sample - loss: 0.6037 - accuracy: 0.8552\n","Epoch 60/200\n","145/145 [==============================] - 0s 110us/sample - loss: 0.6048 - accuracy: 0.8414\n","Epoch 61/200\n","145/145 [==============================] - 0s 112us/sample - loss: 0.6033 - accuracy: 0.8414\n","Epoch 62/200\n","145/145 [==============================] - 0s 110us/sample - loss: 0.6029 - accuracy: 0.8483\n","Epoch 63/200\n","145/145 [==============================] - 0s 98us/sample - loss: 0.6009 - accuracy: 0.8552\n","Epoch 64/200\n","145/145 [==============================] - 0s 102us/sample - loss: 0.6007 - accuracy: 0.8552\n","Epoch 65/200\n","145/145 [==============================] - 0s 156us/sample - loss: 0.5994 - accuracy: 0.8552\n","Epoch 66/200\n","145/145 [==============================] - 0s 108us/sample - loss: 0.6000 - accuracy: 0.8483\n","Epoch 67/200\n","145/145 [==============================] - 0s 104us/sample - loss: 0.5990 - accuracy: 0.8483\n","Epoch 68/200\n","145/145 [==============================] - 0s 121us/sample - loss: 0.5982 - accuracy: 0.8552\n","Epoch 69/200\n","145/145 [==============================] - 0s 118us/sample - loss: 0.5975 - accuracy: 0.8621\n","Epoch 70/200\n","145/145 [==============================] - 0s 128us/sample - loss: 0.5967 - accuracy: 0.8552\n","Epoch 71/200\n","145/145 [==============================] - 0s 98us/sample - loss: 0.5964 - accuracy: 0.8690\n","Epoch 72/200\n","145/145 [==============================] - 0s 94us/sample - loss: 0.5960 - accuracy: 0.8552\n","Epoch 73/200\n","145/145 [==============================] - 0s 105us/sample - loss: 0.5943 - accuracy: 0.8759\n","Epoch 74/200\n","145/145 [==============================] - 0s 91us/sample - loss: 0.5957 - accuracy: 0.8828\n","Epoch 75/200\n","145/145 [==============================] - 0s 128us/sample - loss: 0.5948 - accuracy: 0.8621\n","Epoch 76/200\n","145/145 [==============================] - 0s 118us/sample - loss: 0.5948 - accuracy: 0.8621\n","Epoch 77/200\n","145/145 [==============================] - 0s 120us/sample - loss: 0.5926 - accuracy: 0.8759\n","Epoch 78/200\n","145/145 [==============================] - 0s 117us/sample - loss: 0.5925 - accuracy: 0.8759\n","Epoch 79/200\n","145/145 [==============================] - 0s 125us/sample - loss: 0.5916 - accuracy: 0.8759\n","Epoch 80/200\n","145/145 [==============================] - 0s 140us/sample - loss: 0.5913 - accuracy: 0.8828\n","Epoch 81/200\n","145/145 [==============================] - 0s 101us/sample - loss: 0.5907 - accuracy: 0.8828\n","Epoch 82/200\n","145/145 [==============================] - 0s 122us/sample - loss: 0.5918 - accuracy: 0.8759\n","Epoch 83/200\n","145/145 [==============================] - 0s 103us/sample - loss: 0.5913 - accuracy: 0.8759\n","Epoch 84/200\n","145/145 [==============================] - 0s 103us/sample - loss: 0.5899 - accuracy: 0.8897\n","Epoch 85/200\n","145/145 [==============================] - 0s 114us/sample - loss: 0.5887 - accuracy: 0.8828\n","Epoch 86/200\n","145/145 [==============================] - 0s 139us/sample - loss: 0.5891 - accuracy: 0.8828\n","Epoch 87/200\n","145/145 [==============================] - 0s 116us/sample - loss: 0.5878 - accuracy: 0.8828\n","Epoch 88/200\n","145/145 [==============================] - 0s 105us/sample - loss: 0.5882 - accuracy: 0.8897\n","Epoch 89/200\n","145/145 [==============================] - 0s 106us/sample - loss: 0.5872 - accuracy: 0.8966\n","Epoch 90/200\n","145/145 [==============================] - 0s 116us/sample - loss: 0.5871 - accuracy: 0.8897\n","Epoch 91/200\n","145/145 [==============================] - 0s 143us/sample - loss: 0.5866 - accuracy: 0.8897\n","Epoch 92/200\n","145/145 [==============================] - 0s 124us/sample - loss: 0.5870 - accuracy: 0.8897\n","Epoch 93/200\n","145/145 [==============================] - 0s 105us/sample - loss: 0.5866 - accuracy: 0.8966\n","Epoch 94/200\n","145/145 [==============================] - 0s 101us/sample - loss: 0.5858 - accuracy: 0.8897\n","Epoch 95/200\n","145/145 [==============================] - 0s 96us/sample - loss: 0.5857 - accuracy: 0.8897\n","Epoch 96/200\n","145/145 [==============================] - 0s 122us/sample - loss: 0.5848 - accuracy: 0.8966\n","Epoch 97/200\n","145/145 [==============================] - 0s 117us/sample - loss: 0.5851 - accuracy: 0.9034\n","Epoch 98/200\n","145/145 [==============================] - 0s 119us/sample - loss: 0.5843 - accuracy: 0.9034\n","Epoch 99/200\n","145/145 [==============================] - 0s 115us/sample - loss: 0.5843 - accuracy: 0.8897\n","Epoch 100/200\n","145/145 [==============================] - 0s 130us/sample - loss: 0.5843 - accuracy: 0.8897\n","Epoch 101/200\n","145/145 [==============================] - 0s 105us/sample - loss: 0.5837 - accuracy: 0.9034\n","Epoch 102/200\n","145/145 [==============================] - 0s 164us/sample - loss: 0.5841 - accuracy: 0.9034\n","Epoch 103/200\n","145/145 [==============================] - 0s 107us/sample - loss: 0.5835 - accuracy: 0.8897\n","Epoch 104/200\n","145/145 [==============================] - 0s 136us/sample - loss: 0.5837 - accuracy: 0.8897\n","Epoch 105/200\n","145/145 [==============================] - 0s 123us/sample - loss: 0.5829 - accuracy: 0.8966\n","Epoch 106/200\n","145/145 [==============================] - 0s 171us/sample - loss: 0.5832 - accuracy: 0.9034\n","Epoch 107/200\n","145/145 [==============================] - 0s 128us/sample - loss: 0.5821 - accuracy: 0.9034\n","Epoch 108/200\n","145/145 [==============================] - 0s 96us/sample - loss: 0.5822 - accuracy: 0.8966\n","Epoch 109/200\n","145/145 [==============================] - 0s 114us/sample - loss: 0.5820 - accuracy: 0.9034\n","Epoch 110/200\n","145/145 [==============================] - 0s 117us/sample - loss: 0.5816 - accuracy: 0.9034\n","Epoch 111/200\n","145/145 [==============================] - 0s 105us/sample - loss: 0.5814 - accuracy: 0.8966\n","Epoch 112/200\n","145/145 [==============================] - 0s 102us/sample - loss: 0.5821 - accuracy: 0.9034\n","Epoch 113/200\n","145/145 [==============================] - 0s 129us/sample - loss: 0.5810 - accuracy: 0.9034\n","Epoch 114/200\n","145/145 [==============================] - 0s 124us/sample - loss: 0.5809 - accuracy: 0.8966\n","Epoch 115/200\n","145/145 [==============================] - 0s 116us/sample - loss: 0.5808 - accuracy: 0.9103\n","Epoch 116/200\n","145/145 [==============================] - 0s 121us/sample - loss: 0.5798 - accuracy: 0.9103\n","Epoch 117/200\n","145/145 [==============================] - 0s 127us/sample - loss: 0.5800 - accuracy: 0.9034\n","Epoch 118/200\n","145/145 [==============================] - 0s 112us/sample - loss: 0.5793 - accuracy: 0.9103\n","Epoch 119/200\n","145/145 [==============================] - 0s 121us/sample - loss: 0.5796 - accuracy: 0.9034\n","Epoch 120/200\n","145/145 [==============================] - 0s 110us/sample - loss: 0.5788 - accuracy: 0.9103\n","Epoch 121/200\n","145/145 [==============================] - 0s 117us/sample - loss: 0.5791 - accuracy: 0.9103\n","Epoch 122/200\n","145/145 [==============================] - 0s 109us/sample - loss: 0.5788 - accuracy: 0.9103\n","Epoch 123/200\n","145/145 [==============================] - 0s 125us/sample - loss: 0.5785 - accuracy: 0.9103\n","Epoch 124/200\n","145/145 [==============================] - 0s 130us/sample - loss: 0.5782 - accuracy: 0.9103\n","Epoch 125/200\n","145/145 [==============================] - 0s 114us/sample - loss: 0.5785 - accuracy: 0.9103\n","Epoch 126/200\n","145/145 [==============================] - 0s 110us/sample - loss: 0.5779 - accuracy: 0.9103\n","Epoch 127/200\n","145/145 [==============================] - 0s 152us/sample - loss: 0.5777 - accuracy: 0.9103\n","Epoch 128/200\n","145/145 [==============================] - 0s 120us/sample - loss: 0.5775 - accuracy: 0.9103\n","Epoch 129/200\n","145/145 [==============================] - 0s 121us/sample - loss: 0.5777 - accuracy: 0.9103\n","Epoch 130/200\n","145/145 [==============================] - 0s 155us/sample - loss: 0.5779 - accuracy: 0.9103\n","Epoch 131/200\n","145/145 [==============================] - 0s 118us/sample - loss: 0.5769 - accuracy: 0.9103\n","Epoch 132/200\n","145/145 [==============================] - 0s 112us/sample - loss: 0.5776 - accuracy: 0.9103\n","Epoch 133/200\n","145/145 [==============================] - 0s 127us/sample - loss: 0.5768 - accuracy: 0.9103\n","Epoch 134/200\n","145/145 [==============================] - 0s 136us/sample - loss: 0.5777 - accuracy: 0.9103\n","Epoch 135/200\n","145/145 [==============================] - 0s 119us/sample - loss: 0.5773 - accuracy: 0.9103\n","Epoch 136/200\n","145/145 [==============================] - 0s 122us/sample - loss: 0.5764 - accuracy: 0.9103\n","Epoch 137/200\n","145/145 [==============================] - 0s 281us/sample - loss: 0.5766 - accuracy: 0.9103\n","Epoch 138/200\n","145/145 [==============================] - 0s 145us/sample - loss: 0.5762 - accuracy: 0.9103\n","Epoch 139/200\n","145/145 [==============================] - 0s 115us/sample - loss: 0.5765 - accuracy: 0.9103\n","Epoch 140/200\n","145/145 [==============================] - 0s 98us/sample - loss: 0.5760 - accuracy: 0.9103\n","Epoch 141/200\n","145/145 [==============================] - 0s 109us/sample - loss: 0.5766 - accuracy: 0.9103\n","Epoch 142/200\n","145/145 [==============================] - 0s 103us/sample - loss: 0.5762 - accuracy: 0.9103\n","Epoch 143/200\n","145/145 [==============================] - 0s 141us/sample - loss: 0.5758 - accuracy: 0.9103\n","Epoch 144/200\n","145/145 [==============================] - 0s 131us/sample - loss: 0.5760 - accuracy: 0.9103\n","Epoch 145/200\n","145/145 [==============================] - 0s 114us/sample - loss: 0.5754 - accuracy: 0.9103\n","Epoch 146/200\n","145/145 [==============================] - 0s 128us/sample - loss: 0.5755 - accuracy: 0.9103\n","Epoch 147/200\n","145/145 [==============================] - 0s 109us/sample - loss: 0.5759 - accuracy: 0.9103\n","Epoch 148/200\n","145/145 [==============================] - 0s 136us/sample - loss: 0.5753 - accuracy: 0.9103\n","Epoch 149/200\n","145/145 [==============================] - 0s 100us/sample - loss: 0.5756 - accuracy: 0.9103\n","Epoch 150/200\n","145/145 [==============================] - 0s 109us/sample - loss: 0.5757 - accuracy: 0.9103\n","Epoch 151/200\n","145/145 [==============================] - 0s 113us/sample - loss: 0.5757 - accuracy: 0.9103\n","Epoch 152/200\n","145/145 [==============================] - 0s 123us/sample - loss: 0.5750 - accuracy: 0.9103\n","Epoch 153/200\n","145/145 [==============================] - 0s 100us/sample - loss: 0.5748 - accuracy: 0.9103\n","Epoch 154/200\n","145/145 [==============================] - 0s 108us/sample - loss: 0.5747 - accuracy: 0.9103\n","Epoch 155/200\n","145/145 [==============================] - 0s 117us/sample - loss: 0.5746 - accuracy: 0.9103\n","Epoch 156/200\n","145/145 [==============================] - 0s 131us/sample - loss: 0.5743 - accuracy: 0.9172\n","Epoch 157/200\n","145/145 [==============================] - 0s 145us/sample - loss: 0.5742 - accuracy: 0.9103\n","Epoch 158/200\n","145/145 [==============================] - 0s 122us/sample - loss: 0.5742 - accuracy: 0.9172\n","Epoch 159/200\n","145/145 [==============================] - 0s 113us/sample - loss: 0.5743 - accuracy: 0.9103\n","Epoch 160/200\n","145/145 [==============================] - 0s 128us/sample - loss: 0.5741 - accuracy: 0.9103\n","Epoch 161/200\n","145/145 [==============================] - 0s 103us/sample - loss: 0.5743 - accuracy: 0.9172\n","Epoch 162/200\n","145/145 [==============================] - 0s 142us/sample - loss: 0.5745 - accuracy: 0.9103\n","Epoch 163/200\n","145/145 [==============================] - 0s 126us/sample - loss: 0.5747 - accuracy: 0.9172\n","Epoch 164/200\n","145/145 [==============================] - 0s 113us/sample - loss: 0.5740 - accuracy: 0.9172\n","Epoch 165/200\n","145/145 [==============================] - 0s 125us/sample - loss: 0.5740 - accuracy: 0.9103\n","Epoch 166/200\n","145/145 [==============================] - 0s 91us/sample - loss: 0.5733 - accuracy: 0.9172\n","Epoch 167/200\n","145/145 [==============================] - 0s 112us/sample - loss: 0.5734 - accuracy: 0.9172\n","Epoch 168/200\n","145/145 [==============================] - 0s 110us/sample - loss: 0.5737 - accuracy: 0.9103\n","Epoch 169/200\n","145/145 [==============================] - 0s 121us/sample - loss: 0.5734 - accuracy: 0.9172\n","Epoch 170/200\n","145/145 [==============================] - 0s 139us/sample - loss: 0.5733 - accuracy: 0.9172\n","Epoch 171/200\n","145/145 [==============================] - 0s 124us/sample - loss: 0.5739 - accuracy: 0.9103\n","Epoch 172/200\n","145/145 [==============================] - 0s 149us/sample - loss: 0.5734 - accuracy: 0.9172\n","Epoch 173/200\n","145/145 [==============================] - 0s 127us/sample - loss: 0.5733 - accuracy: 0.9172\n","Epoch 174/200\n","145/145 [==============================] - 0s 130us/sample - loss: 0.5734 - accuracy: 0.9172\n","Epoch 175/200\n","145/145 [==============================] - 0s 138us/sample - loss: 0.5727 - accuracy: 0.9172\n","Epoch 176/200\n","145/145 [==============================] - 0s 111us/sample - loss: 0.5729 - accuracy: 0.9172\n","Epoch 177/200\n","145/145 [==============================] - 0s 129us/sample - loss: 0.5724 - accuracy: 0.9172\n","Epoch 178/200\n","145/145 [==============================] - 0s 117us/sample - loss: 0.5731 - accuracy: 0.9172\n","Epoch 179/200\n","145/145 [==============================] - 0s 123us/sample - loss: 0.5738 - accuracy: 0.9172\n","Epoch 180/200\n","145/145 [==============================] - 0s 116us/sample - loss: 0.5718 - accuracy: 0.9172\n","Epoch 181/200\n","145/145 [==============================] - 0s 142us/sample - loss: 0.5723 - accuracy: 0.9172\n","Epoch 182/200\n","145/145 [==============================] - 0s 130us/sample - loss: 0.5721 - accuracy: 0.9172\n","Epoch 183/200\n","145/145 [==============================] - 0s 129us/sample - loss: 0.5723 - accuracy: 0.9172\n","Epoch 184/200\n","145/145 [==============================] - 0s 118us/sample - loss: 0.5715 - accuracy: 0.9172\n","Epoch 185/200\n","145/145 [==============================] - 0s 140us/sample - loss: 0.5712 - accuracy: 0.9172\n","Epoch 186/200\n","145/145 [==============================] - 0s 129us/sample - loss: 0.5708 - accuracy: 0.9241\n","Epoch 187/200\n","145/145 [==============================] - 0s 129us/sample - loss: 0.5706 - accuracy: 0.9241\n","Epoch 188/200\n","145/145 [==============================] - 0s 97us/sample - loss: 0.5708 - accuracy: 0.9241\n","Epoch 189/200\n","145/145 [==============================] - 0s 101us/sample - loss: 0.5707 - accuracy: 0.9241\n","Epoch 190/200\n","145/145 [==============================] - 0s 142us/sample - loss: 0.5710 - accuracy: 0.9241\n","Epoch 191/200\n","145/145 [==============================] - 0s 114us/sample - loss: 0.5705 - accuracy: 0.9241\n","Epoch 192/200\n","145/145 [==============================] - 0s 166us/sample - loss: 0.5707 - accuracy: 0.9241\n","Epoch 193/200\n","145/145 [==============================] - 0s 123us/sample - loss: 0.5706 - accuracy: 0.9241\n","Epoch 194/200\n","145/145 [==============================] - 0s 158us/sample - loss: 0.5698 - accuracy: 0.9241\n","Epoch 195/200\n","145/145 [==============================] - 0s 104us/sample - loss: 0.5699 - accuracy: 0.9241\n","Epoch 196/200\n","145/145 [==============================] - 0s 134us/sample - loss: 0.5698 - accuracy: 0.9241\n","Epoch 197/200\n","145/145 [==============================] - 0s 131us/sample - loss: 0.5698 - accuracy: 0.9241\n","Epoch 198/200\n","145/145 [==============================] - 0s 113us/sample - loss: 0.5696 - accuracy: 0.9241\n","Epoch 199/200\n","145/145 [==============================] - 0s 97us/sample - loss: 0.5695 - accuracy: 0.9241\n","Epoch 200/200\n","145/145 [==============================] - 0s 123us/sample - loss: 0.5694 - accuracy: 0.9241\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd47a8573c8>"]},"metadata":{"tags":[]},"execution_count":144}]},{"cell_type":"code","metadata":{"id":"trg9nAhm9zyG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1581442704007,"user_tz":300,"elapsed":395,"user":{"displayName":"Manoj Malviya","photoUrl":"","userId":"00270539278112484716"}},"outputId":"d796ee18-6012-4709-9a04-e7e9afe75e77"},"source":["# Evaluating MODEL PERFORMANCE ON TEST DATA\n","model.evaluate(Input_test,Target_test)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["63/63 [==============================] - 0s 87us/sample - loss: 0.5686 - accuracy: 0.7460\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.5685618926608373, 0.74603176]"]},"metadata":{"tags":[]},"execution_count":142}]}]}